# EMOTION-RECOGNITON

<h3>ABOUT THE PROJECT:</h3>
<p style="font-size:20px;"> Live emotion detection that can accommodate detection of more than one person's emotion.</p>
<br>
<h3> PROJECT MEMBERS:</h3>

<ol type="1">
  <li><a href= "https://github.com/priyanshmehta22", target="_blank">PRIYANSH MEHTA</a></li>
  <li><a href="https://github.com/anoushka22", target="_blank">ANOUSHKA SHRESTH</a></li>
  <li><a href="https://github.com/Ekjot07", target="_blank"> EKJOT SINGH</a></li>
  <li>ADITYA MOHITE</li>
  <li><a href="https://github.com/Rashi-2602", target="_blank">RASHI PANT</a></li>
  <p align="center">
    <img src="https://media.giphy.com/media/8c3LWBENZHRnP6ixOc/giphy.gif" width="500px"></p>

<hr>
<h3> LIBRARIES USED: </h3>
<ul>
  <li>numpy</li>
  <li>pandas</li>
  <li>progressbar</li>
  <li>tensorflow</li>
  <li>cv2</li>
  <li>imutils</li>
  <li>sklearn</li>
</ul>
  <br>
  <h3> INTRODUCTION</h3>
  <p>Facial emotion recognition is a technology which uses biometric markers to detect emotions in human faces. More precisely, this technology is a sentiment analysis tool and is able to automatically detect the six basic or universal expressions: happiness, sadness, anger, surprise, fear, and disgust. Computer-based facial expression recognition systems are important because of their ability to mimic human coding skills. Facial emotion and other gestures convey nonverbal communication cues that play an important role in interpersonal relations. These cues complement speech by helping the listener to interpret the intended meaning of spoken words. Therefore, facial emotion recognition, because it extracts and analyzes information from an image or video feed, is able to deliver unfiltered, unbiased emotional responses as input data via webcam of the device used.</p>
  <br>
  <ol type="1">
    <li>
  <h4>Face detection</h4></li>
  <p>Locating faces in the scene, in an image or video footage with the help of the webcam used by the computer as input. The output is the bounding box coordinates of the detected faces.</p>

  <li><h4>Facial landmark detection</h4></li>
  <p> Extracting information about facial features from detected faces. For example, detecting the shape of facial components or describing the texture of the skin in a facial area with the help of pixel formations which is appended into arrays and is then used to detect emotion.</p>
 
  <li><h4>Facial expression and emotion classification</h4></li>
  <p>Analyzing the movement of facial features and/or changes in the appearance of facial features and classifying this information into emotion-interpretative categories such as facial muscle activations like smile or frown; emotion categories happiness or anger; attitude categories like (dis)liking or ambivalence.</p>
<br>
  <p align="center">
    <img src="https://miro.medium.com/max/543/1*6xp-IY-M8lEEEN0UuUBq0w.jpeg" ></p>
  
                                                                   
  
